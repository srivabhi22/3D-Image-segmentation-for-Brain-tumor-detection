{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif \n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:13.480183Z","iopub.execute_input":"2024-07-01T10:51:13.481028Z","iopub.status.idle":"2024-07-01T10:51:13.484965Z","shell.execute_reply.started":"2024-07-01T10:51:13.480995Z","shell.execute_reply":"2024-07-01T10:51:13.484082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport cv2\nimport glob\nimport PIL\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage.util import montage \nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nfrom PIL import Image, ImageOps \nimport plotly.express as px\nimport pydot,graphviz\n\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\nimport gif_your_nifti.core as gif2nif\n\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras import preprocessing\nnp.set_printoptions(precision=3, suppress=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:22.628197Z","iopub.execute_input":"2024-07-01T10:51:22.628611Z","iopub.status.idle":"2024-07-01T10:51:45.682277Z","shell.execute_reply.started":"2024-07-01T10:51:22.628577Z","shell.execute_reply":"2024-07-01T10:51:45.681509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_flair=nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\ntest_image_t1=nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\ntest_image_t1ce=nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\ntest_image_t2=nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\ntest_mask=nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\ntest_mask=test_mask.astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:45.683959Z","iopub.execute_input":"2024-07-01T10:51:45.684608Z","iopub.status.idle":"2024-07-01T10:51:47.016513Z","shell.execute_reply.started":"2024-07-01T10:51:45.684579Z","shell.execute_reply":"2024-07-01T10:51:47.015467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEGMENT_CLASSES = {\n    0 : 'NO TUMOUR',\n    1 : 'NECROTIC/CORE',\n    2 : 'EDEMA',\n    3 : 'ENHANCING'\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:47.017819Z","iopub.execute_input":"2024-07-01T10:51:47.018181Z","iopub.status.idle":"2024-07-01T10:51:47.022790Z","shell.execute_reply.started":"2024-07-01T10:51:47.018145Z","shell.execute_reply":"2024-07-01T10:51:47.021927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_slice=random.randint(0, test_mask.shape[2]-1)\nprint(n_slice)\n\nplt.figure(figsize=(12, 8))\n# n_slice=28\n\nplt.subplot(231)\nplt.imshow(test_image_flair[:,:,n_slice])\nplt.title('Image flair')\nplt.axis('off')\n\nplt.subplot(232)\nplt.imshow(test_image_t1[:,:,n_slice])\nplt.title('Image t1')\nplt.axis('off')\n\nplt.subplot(233)\nplt.imshow(test_image_t1ce[:,:,n_slice])\nplt.title('Image t1ce')\nplt.axis('off')\n\nplt.subplot(234)\nplt.imshow(test_image_t2[:,:,n_slice])\nplt.title('Image t2')\nplt.axis('off')\n\nplt.subplot(235)\nplt.imshow(test_mask[:,:,n_slice])\nplt.title('Mask')\nplt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:47.024678Z","iopub.execute_input":"2024-07-01T10:51:47.025067Z","iopub.status.idle":"2024-07-01T10:51:47.823260Z","shell.execute_reply.started":"2024-07-01T10:51:47.025042Z","shell.execute_reply":"2024-07-01T10:51:47.822373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values,counts=np.unique(test_mask[:,:,n_slice],return_counts=True)\ndata = pd.DataFrame({'Value': unique_values, 'Count': counts})\ndata['Type']=np.where(data['Value']==0,SEGMENT_CLASSES[0],np.where(data['Value']==1,SEGMENT_CLASSES[1],np.where(data['Value']==2,SEGMENT_CLASSES[2],SEGMENT_CLASSES[3])))\n# Calculate percentage composition\ndata['Percentage'] = (data['Count'] / data['Count'].sum()) * 100\n\n# Plotting with Plotly\nfig = px.pie(data, values='Percentage', names='Type', title='Percentage Composition of tumour present in the brain')\n# fig.update_yaxes(type='log')\n\n# Show the plot\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:47.824475Z","iopub.execute_input":"2024-07-01T10:51:47.824765Z","iopub.status.idle":"2024-07-01T10:51:50.021441Z","shell.execute_reply.started":"2024-07-01T10:51:47.824739Z","shell.execute_reply":"2024-07-01T10:51:50.020360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH='/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\nTEST_DATASET_PATH='/kaggle/input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/'\n\ntrain_img_dir=os.listdir(TRAIN_DATASET_PATH)\ntrain_img_dir=os.listdir(TRAIN_DATASET_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:50.022634Z","iopub.execute_input":"2024-07-01T10:51:50.022979Z","iopub.status.idle":"2024-07-01T10:51:50.136735Z","shell.execute_reply.started":"2024-07-01T10:51:50.022952Z","shell.execute_reply":"2024-07-01T10:51:50.136025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN_DATASET_PATH='/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n# shutil.copy2(TRAIN_DATASET_PATH + 'BraTS20_Training_204/BraTS20_Training_204_flair.nii', './test_gif_BraTS20_Training_204_flair.nii')\n# gif2nif.write_gif_normal('./test_gif_BraTS20_Training_204_flair.nii')","metadata":{"execution":{"iopub.status.busy":"2024-06-29T13:18:20.980031Z","iopub.execute_input":"2024-06-29T13:18:20.980499Z","iopub.status.idle":"2024-06-29T13:18:20.985583Z","shell.execute_reply.started":"2024-06-29T13:18:20.980458Z","shell.execute_reply":"2024-06-29T13:18:20.984369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii')\n\nfig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n\nnlplt.plot_anat(niimg,\n                title='BraTS20_Training_001_flair.nii plot_anat',\n                axes=axes[0])\n\nnlplt.plot_epi(niimg,\n               title='BraTS20_Training_001_flair.nii plot_epi',\n               axes=axes[1])\n\nnlplt.plot_img(niimg,\n               title='BraTS20_Training_001_flair.nii plot_img',\n               axes=axes[2])\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T21:57:22.959639Z","iopub.execute_input":"2024-06-30T21:57:22.960104Z","iopub.status.idle":"2024-06-30T21:57:22.966799Z","shell.execute_reply.started":"2024-06-30T21:57:22.960070Z","shell.execute_reply":"2024-06-30T21:57:22.965546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    class_num = 4\n    dice = 0\n    for i in range(class_num):\n        y_true_f = tf.keras.backend.flatten(y_true[:,:,:,i])\n        y_pred_f = tf.keras.backend.flatten(y_pred[:,:,:,i])\n        intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n        dice += (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n    return dice / class_num\n\n\n \n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (tf.keras.backend.sum(tf.keras.backend.square(y_true[:,:,:,1])) + tf.keras.backend.sum(tf.keras.backend.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (tf.keras.backend.sum(tf.keras.backend.square(y_true[:,:,:,2])) + tf.keras.backend.sum(tf.keras.backend.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (tf.keras.backend.sum(tf.keras.backend.square(y_true[:,:,:,3])) + tf.keras.backend.sum(tf.keras.backend.square(y_pred[:,:,:,3])) + epsilon)\n\ndef precision(y_true, y_pred):\n    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    return precision\n\ndef sensitivity(y_true, y_pred):\n    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + tf.keras.backend.epsilon())\n\ndef specificity(y_true, y_pred):\n    true_negatives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + tf.keras.backend.epsilon())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:50.137938Z","iopub.execute_input":"2024-07-01T10:51:50.138552Z","iopub.status.idle":"2024-07-01T10:51:50.156254Z","shell.execute_reply.started":"2024-07-01T10:51:50.138518Z","shell.execute_reply":"2024-07-01T10:51:50.155383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(64, 7, activation='relu', padding='same', kernel_initializer=ker_init)(inputs)\n    conv1 = Conv2D(64, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv1)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 7, activation='relu', padding='same', kernel_initializer=ker_init)(pool1)\n    conv2 = Conv2D(128, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 7, activation='relu', padding='same', kernel_initializer=ker_init)(pool2)\n    conv3 = Conv2D(256, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv3)\n    \n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 7, activation='relu', padding='same', kernel_initializer=ker_init)(pool3)\n    conv4 = Conv2D(512, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv4)\n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv5 = Conv2D(1024, 7, activation='relu', padding='same', kernel_initializer=ker_init)(pool4)\n    conv5 = Conv2D(1024, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer=ker_init)(UpSampling2D(size=(2,2))(drop5))\n    merge6 = concatenate([conv4, up6], axis=3)\n    conv6 = Conv2D(512, 7, activation='relu', padding='same', kernel_initializer=ker_init)(merge6)\n    conv6 = Conv2D(512, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv6)\n\n    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer=ker_init)(UpSampling2D(size=(2,2))(conv6))\n    merge7 = concatenate([conv3, up7], axis=3)\n    conv7 = Conv2D(256, 7, activation='relu', padding='same', kernel_initializer=ker_init)(merge7)\n    conv7 = Conv2D(256, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer=ker_init)(UpSampling2D(size=(2,2))(conv7))\n    merge8 = concatenate([conv2, up8], axis=3)\n    conv8 = Conv2D(128, 7, activation='relu', padding='same', kernel_initializer=ker_init)(merge8)\n    conv8 = Conv2D(128, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer=ker_init)(UpSampling2D(size=(2,2))(conv8))\n    merge9 = concatenate([conv1, up9], axis=3)\n    conv9 = Conv2D(64, 7, activation='relu', padding='same', kernel_initializer=ker_init)(merge9)\n    conv9 = Conv2D(64, 7, activation='relu', padding='same', kernel_initializer=ker_init)(conv9)\n\n    conv10 = Conv2D(4, 1, activation='softmax')(conv9)\n\n    return Model(inputs=inputs, outputs=conv10)\n\nIMG_SIZE = 128 \ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(inputs=input_layer,ker_init='he_normal',dropout=0.1)\nmodel.compile(\n    loss=\"categorical_crossentropy\", \n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n    metrics=[\n        'accuracy',\n        tf.keras.metrics.MeanIoU(num_classes=4),\n        dice_coef, precision, sensitivity, specificity,\n        dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing\n    ]\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:51:50.157393Z","iopub.execute_input":"2024-07-01T10:51:50.157673Z","iopub.status.idle":"2024-07-01T10:51:51.524002Z","shell.execute_reply.started":"2024-07-01T10:51:50.157649Z","shell.execute_reply":"2024-07-01T10:51:51.523076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n\nimport plotly.graph_objects as go\n\n# Define a function to create an interactive plot of the model\ndef plot_model_interactive(model):\n    fig = go.Figure()\n\n    # Iterate over the layers and add them to the plot\n    for i, layer in enumerate(model.layers):\n        fig.add_trace(go.Scatter(\n            x=[i],\n            y=[0],\n            mode='markers+text',\n            text=[layer.name],\n            textposition='bottom center',\n            marker=dict(size=20)\n        ))\n\n    # Set plot layout\n    fig.update_layout(\n        title='Interactive Model Schematic',\n        xaxis_title='Layer',\n        yaxis_title='Position',\n        showlegend=False\n    )\n\n    fig.show()\n\n# Plot the model interactively\nplot_model_interactive(model)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:52:57.201449Z","iopub.execute_input":"2024-07-01T10:52:57.201848Z","iopub.status.idle":"2024-07-01T10:52:57.237755Z","shell.execute_reply.started":"2024-07-01T10:52:57.201810Z","shell.execute_reply":"2024-07-01T10:52:57.236815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\n# As because file BraTS20_Training_355 has ill formatted name for for seg.nii file\ntrain_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories)\n\n    \ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2, random_state=2)  # splitting the data into training and validation data\ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15, random_state=42) # splitting the train_test data into train and test data","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:53:10.704290Z","iopub.execute_input":"2024-07-01T10:53:10.704673Z","iopub.status.idle":"2024-07-01T10:53:10.715797Z","shell.execute_reply.started":"2024-07-01T10:53:10.704646Z","shell.execute_reply":"2024-07-01T10:53:10.715039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.transform import factor_cmap\nfrom bokeh.palettes import Spectral6\n\nlabels = ['train', 'val', 'test']\ncounts = [len(train_ids),len(val_ids),len(test_ids)]\n\nsource = ColumnDataSource(data=dict(labels=labels, counts=counts))\n\np = figure(x_range=labels,height=400, width=600, title=\"Distribution of data for training, validation and testing\",\n           toolbar_location=None, tools=\"\")\n\np.vbar(x='labels', top='counts', width=0.5, source=source, legend_field=\"labels\",\n       line_color='white', fill_color=factor_cmap('labels', palette=Spectral6, factors=labels))\n\np.xgrid.grid_line_color = None\np.y_range.start = 0\np.legend.orientation = \"horizontal\"\np.legend.location = \"top_center\"\n\noutput_notebook()\nshow(p)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:53:22.755605Z","iopub.execute_input":"2024-07-01T10:53:22.755969Z","iopub.status.idle":"2024-07-01T10:53:23.586682Z","shell.execute_reply.started":"2024-07-01T10:53:22.755942Z","shell.execute_reply":"2024-07-01T10:53:23.585774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VOLUME_SLICES = 100 \nVOLUME_START_AT = 22","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:53:42.717647Z","iopub.execute_input":"2024-07-01T10:53:42.718528Z","iopub.status.idle":"2024-07-01T10:53:42.722734Z","shell.execute_reply.started":"2024-07-01T10:53:42.718491Z","shell.execute_reply":"2024-07-01T10:53:42.721561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, volume_slices=VOLUME_SLICES,volume_start=VOLUME_START_AT,dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.volume_slices=volume_slices\n        self.volume_start=volume_start\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*self.volume_slices, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*self.volume_slices, 240, 240))\n        Y = np.zeros((self.batch_size*self.volume_slices, *self.dim, 4))\n\n        \n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(self.volume_slices):\n                 X[j +self.volume_slices*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                 X[j +self.volume_slices*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                 y[j +self.volume_slices*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:53:44.656250Z","iopub.execute_input":"2024-07-01T10:53:44.657150Z","iopub.status.idle":"2024-07-01T10:53:44.674065Z","shell.execute_reply.started":"2024-07-01T10:53:44.657114Z","shell.execute_reply":"2024-07-01T10:53:44.673209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(valid_generator)\nprint(training_generator)\nprint(test_generator)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:53:46.412965Z","iopub.execute_input":"2024-07-01T10:53:46.413557Z","iopub.status.idle":"2024-07-01T10:53:46.418137Z","shell.execute_reply.started":"2024-07-01T10:53:46.413526Z","shell.execute_reply":"2024-07-01T10:53:46.417256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_logger = CSVLogger('training.log', separator=',', append=False)\n\ncallbacks = [\n#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n#                               patience=2, verbose=1, mode='auto'),\n      keras.callbacks.ReduceLROnPlateau(monitor='dice_coef', factor=0.5,\n                              patience=5, min_lr=0.000001, verbose=1),\n# todo add ModelCheckpoint\n  #  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n  #                             verbose=1, save_best_only=True, save_weights_only = True)\n        csv_logger\n    ]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:53:48.807857Z","iopub.execute_input":"2024-07-01T10:53:48.808732Z","iopub.status.idle":"2024-07-01T10:53:48.813729Z","shell.execute_reply.started":"2024-07-01T10:53:48.808698Z","shell.execute_reply":"2024-07-01T10:53:48.812764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\n\nhistory =  model.fit(training_generator,\n                    epochs=38,\n                    steps_per_epoch=len(train_ids),\n                    callbacks= callbacks,\n                    validation_data = valid_generator\n                    )  ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T10:53:51.603287Z","iopub.execute_input":"2024-07-01T10:53:51.603956Z","iopub.status.idle":"2024-07-01T16:29:40.336497Z","shell.execute_reply.started":"2024-07-01T10:53:51.603919Z","shell.execute_reply":"2024-07-01T16:29:40.330042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:31:11.070281Z","iopub.execute_input":"2024-07-01T16:31:11.070668Z","iopub.status.idle":"2024-07-01T16:31:11.339218Z","shell.execute_reply.started":"2024-07-01T16:31:11.070638Z","shell.execute_reply":"2024-07-01T16:31:11.338216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = pd.read_csv('training.log', sep=',', engine='python')\nreport = report[report['accuracy']!=0]\nreport","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:33:32.807364Z","iopub.execute_input":"2024-07-01T16:33:32.808289Z","iopub.status.idle":"2024-07-01T16:33:32.852315Z","shell.execute_reply.started":"2024-07-01T16:33:32.808248Z","shell.execute_reply":"2024-07-01T16:33:32.851302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc=report['accuracy']\nval_acc=report['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=report['loss']\nval_loss=report['val_loss']\n\ntrain_dice=report['dice_coef']\nval_dice=report['val_dice_coef']\n\nf,ax=plt.subplots(1,3,figsize=(16,8))\n\nax[0].plot(epoch,acc,'y',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'g',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'y',label='Training Loss')\nax[1].plot(epoch,val_loss,'g',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'y',label='Training dice coef')\nax[2].plot(epoch,val_dice,'g',label='Validation dice coef')\nax[2].legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:36:20.173463Z","iopub.execute_input":"2024-07-01T16:36:20.173843Z","iopub.status.idle":"2024-07-01T16:36:20.749632Z","shell.execute_reply.started":"2024-07-01T16:36:20.173814Z","shell.execute_reply":"2024-07-01T16:36:20.748676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n# returns volume of specified study at `path`\ndef imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*100, *self.dim, self.n_channels))\n    for j in range(100):\n        X[j +100*c,:,:,0] = cv2.resize(image[:,:,j+22], (IMG_SIZE, IMG_SIZE));\n        X[j +100*c,:,:,1] = cv2.resize(ce[:,:,j+22], (IMG_SIZE, IMG_SIZE));\n\n        y[j +100*c] = seg[:,:,j+22];\n    return np.array(image)\n\n\n# load nifti file at `path`\n# and load each slice with mask from volume\n# choose the mri type & resize to `IMG_SIZE`\ndef loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n        \n#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:37:13.421287Z","iopub.execute_input":"2024-07-01T16:37:13.421689Z","iopub.status.idle":"2024-07-01T16:37:13.433889Z","shell.execute_reply.started":"2024-07-01T16:37:13.421659Z","shell.execute_reply":"2024-07-01T16:37:13.432868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((100, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((100, IMG_SIZE, IMG_SIZE))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    \n    for j in range(100):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+22], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+22], (IMG_SIZE,IMG_SIZE))\n #       y[j,:,:] = cv2.resize(seg[:,:,j+22], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\n\ndef showPredictsById(case, start_slice = 60):\n    path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n\n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+22], (IMG_SIZE, IMG_SIZE)))\n    axarr[0].title.set_text('Original image flair')\n    axarr[1].imshow(cv2.resize(gt[:,:,start_slice+22], (IMG_SIZE, IMG_SIZE)))\n    axarr[1].title.set_text('Ground truth')\n    axarr[3].imshow(edema[start_slice,:,:])\n    axarr[3].title.set_text('edema predicted')\n    axarr[4].imshow(core[start_slice,:,])\n    axarr[4].title.set_text('core predicted')\n    axarr[5].imshow(enhancing[start_slice,:,])\n    axarr[5].title.set_text('enhancing predicted')\n    plt.show()\n    \n    \nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[1][-3:])\nshowPredictsById(case=test_ids[2][-3:])\nshowPredictsById(case=test_ids[3][-3:])\nshowPredictsById(case=test_ids[4][-3:])\nshowPredictsById(case=test_ids[5][-3:])\nshowPredictsById(case=test_ids[6][-3:], start_slice=40)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:42:02.045984Z","iopub.execute_input":"2024-07-01T16:42:02.046724Z","iopub.status.idle":"2024-07-01T16:42:18.202952Z","shell.execute_reply.started":"2024-07-01T16:42:02.046688Z","shell.execute_reply":"2024-07-01T16:42:18.202025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model_1.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T17:13:33.484169Z","iopub.execute_input":"2024-07-01T17:13:33.484596Z","iopub.status.idle":"2024-07-01T17:13:38.901787Z","shell.execute_reply.started":"2024-07-01T17:13:33.484565Z","shell.execute_reply":"2024-07-01T17:13:38.900779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"model.weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T17:15:55.022625Z","iopub.execute_input":"2024-07-01T17:15:55.023489Z","iopub.status.idle":"2024-07-01T17:15:58.772383Z","shell.execute_reply.started":"2024-07-01T17:15:55.023446Z","shell.execute_reply":"2024-07-01T17:15:58.770998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}